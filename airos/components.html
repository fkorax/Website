<html><head><meta charset="utf-8"><title>airOS Components - ATPC</title><meta name="author" content="ATPC"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="../font.css"><link rel="stylesheet" type="text/css" href="../style.css"><link rel="stylesheet" type="text/css" href="style.css"><link rel="shortcut icon" type="image/x-icon" href="../favicon.ico"></head><body><div id="header"><iframe id="backlink" src="http://atpc.one/widget/" frameborder="0" scrolling="no" height="48" width="140"></iframe></div><div id="title"><h1>airOS Components</h1><div class="separator"></div></div></div><div id="components"><p></p><br><p><h2>airOS</h2></p><p align="center">
<br>	<a href="http://atpc.one/airos/"><img src="http://www.atpc.one/airos/airOS-Transparent-Dark.svg" height="160" alt="airOS" /></a>
<br></p>
<br>
<br>![platforms](https://img.shields.io/badge/platforms-x86--64-lightgrey.svg)
<br>
<br># airOS
<br>
<br>airOS is a new, high-level operating system for x86 computers.  
<br>
<br>## Credits
<br>
<br>Copyright (c) 2017 by ATPC  
<br>[Open Source Licenses](http://www.atpc.one/airos/components.html)  
<br>
<br>Throughout the hole project, "corresponding README" is defined as the nearest
<br>README information file containing a legal notice, relative to the file referencing it, whereas "nearest"
<br>means "in the same directory" or "in the nearest directory above".
<br>
<br>### License Files
<br>```
<br>GNU  GPL v3:   gpl-3.0.txt
<br>GNU AGPL v3:  agpl-3.0.txt
<br>GNU LGPL v3:  lgpl-3.0.txt
<br>```
<br><p></p><div class="separator"></div><br><p><h2>xnu</h2></p>What is XNU?
<br>===========
<br>
<br>XNU kernel is part of the Darwin operating system for use in OS X and iOS operating systems. XNU is an acronym for XNU is Not Unix.
<br>XNU is a hybrid kernel combining the Mach kernel developed at Carnegie Mellon University with components from FreeBSD and C++ API for writing drivers called IOKit.
<br>XNU runs on I386, X86_64 for both single processor and multi-processor configurations.
<br>
<br>XNU Source Tree
<br>===============
<br>
<br>  * `config` - configurations for exported apis for supported architecture and platform
<br>  * `SETUP` - Basic set of tools used for configuring the kernel, versioning and kextsymbol management.
<br>  * `EXTERNAL_HEADERS` - Headers sourced from other projects to avoid dependency cycles when building. These headers should be regularly synced when source is updated.
<br>  * `libkern` - C++ IOKit library code for handling of drivers and kexts.
<br>  * `libsa` -  kernel bootstrap code for startup
<br>  * `libsyscall` - syscall library interface for userspace programs
<br>  * `libkdd` - source for user library for parsing kernel data like kernel chunked data.
<br>  * `makedefs` - top level rules and defines for kernel build.
<br>  * `osfmk` - Mach kernel based subsystems
<br>  * `pexpert` - Platform specific code like interrupt handling, atomics etc.
<br>  * `security` - Mandatory Access Check policy interfaces and related implementation.
<br>  * `bsd` - BSD subsystems code
<br>  * `tools` - A set of utilities for testing, debugging and profiling kernel.
<br>
<br>How to build XNU
<br>================
<br>
<br>Building `DEVELOPMENT` kernel
<br>-----------------------------
<br>
<br>The xnu make system can build kernel based on `KERNEL_CONFIGS` & `ARCH_CONFIGS` variables as arguments.
<br>Here is the syntax:
<br>
<br>    make SDKROOT=<sdkroot> ARCH_CONFIGS=<arch> KERNEL_CONFIGS=<variant>
<br>
<br>Where:
<br>
<br>  * \<sdkroot>: path to MacOS SDK on disk. (defaults to `/`)
<br>  * \<variant>: can be `debug`, `development`, `release`, `profile` and configures compilation flags and asserts throughout kernel code.
<br>  * \<arch>   : can be valid arch to build for. (E.g. `i386` or `X86_64`)
<br>
<br>To build a kernel for the same architecture as running OS, just type
<br>
<br>    $ make
<br>    $ make SDKROOT=macosx.internal
<br>
<br>Additionally, there is support for configuring architectures through `ARCH_CONFIGS` and kernel configurations with `KERNEL_CONFIGS`.
<br>
<br>    $ make SDKROOT=macosx.internal ARCH_CONFIGS=X86_64 KERNEL_CONFIGS=DEVELOPMENT
<br>    $ make SDKROOT=macosx.internal ARCH_CONFIGS=X86_64 KERNEL_CONFIGS="RELEASE DEVELOPMENT DEBUG"
<br>
<br>
<br>Note:
<br>  * By default, architecture is set to the build machine architecture, and the default kernel
<br>    config is set to build for DEVELOPMENT.
<br>
<br>
<br>This will also create a bootable image, kernel.[config],  and a kernel binary
<br>with symbols, kernel.[config].unstripped.
<br>
<br>
<br>  * To build with RELEASE kernel configuration
<br>
<br>        make KERNEL_CONFIGS=RELEASE SDKROOT=/path/to/SDK
<br>
<br>
<br>Building FAT kernel binary
<br>--------------------------
<br>
<br>Define architectures in your environment or when running a make command.
<br>
<br>    $ make ARCH_CONFIGS="I386 X86_64" exporthdrs all
<br>
<br>Other makefile options
<br>----------------------
<br>
<br> * $ make MAKEJOBS=-j8    # this will use 8 processes during the build. The default is 2x the number of active CPUS.
<br> * $ make -j8             # the standard command-line option is also accepted
<br> * $ make -w              # trace recursive make invocations. Useful in combination with VERBOSE=YES
<br> * $ make BUILD_LTO=0      # build without LLVM Link Time Optimization
<br> * $ make REMOTEBUILD=user@remotehost # perform build on remote host
<br> * $ make BUILD_JSON_COMPILATION_DATABASE=1 # Build Clang JSON Compilation Database
<br>
<br>
<br>
<br>Debug information formats
<br>=========================
<br>
<br>By default, a DWARF debug information repository is created during the install phase; this is a "bundle" named kernel.development.\<variant>.dSYM
<br>To select the older STABS debug information format (where debug information is embedded in the kernel.development.unstripped image), set the BUILD_STABS environment variable.
<br>
<br>    $ export BUILD_STABS=1
<br>    $ make
<br>
<br>
<br>Building KernelCaches
<br>=====================
<br>
<br>To test the xnu kernel, you need to build a kernelcache that links the kexts and
<br>kernel together into a single bootable image.
<br>To build a kernelcache you can use the following mechanisms:
<br>
<br>  * Using automatic kernelcache generation with `kextd`.
<br>    The kextd daemon keeps watching for changing in `/System/Library/Extensions` directory. 
<br>    So you can setup new kernel as
<br>
<br>        $ cp BUILD/obj/DEVELOPMENT/X86_64/kernel.development /System/Library/Kernels/
<br>        $ touch /System/Library/Extensions
<br>        $ ps -e | grep kextd
<br>
<br>  * Manually invoking `kextcache` to build new kernelcache.
<br>
<br>        $ kextcache -q -z -a x86_64 -l -n -c /var/tmp/kernelcache.test -K /var/tmp/kernel.test /System/Library/Extensions
<br>
<br>
<br>
<br>Running KernelCache on Target machine
<br>=====================================
<br>
<br>The development kernel and iBoot supports configuring boot arguments so that we can safely boot into test kernel and, if things go wrong, safely fall back to previously used kernelcache.
<br>Following are the steps to get such a setup:
<br>
<br>  1. Create kernel cache using the kextcache command as `/kernelcache.test`
<br>  2. Copy exiting boot configurations to alternate file
<br>
<br>         $ cp /Library/Preferences/SystemConfiguration/com.apple.Boot.plist /next_boot.plist
<br>
<br>  3. Update the kernelcache and boot-args for your setup
<br>
<br>         $ plutil -insert "Kernel Cache" -string "kernelcache.test" /next_boot.plist
<br>         $ plutil -replace "Kernel Flags" -string "debug=0x144 -v kernelsuffix=test " /next_boot.plist
<br>
<br>  4. Copy the new config to `/Library/Preferences/SystemConfiguration/`
<br>
<br>         $ cp /next_boot.plist /Library/Preferences/SystemConfiguration/boot.plist
<br>
<br>  5. Bless the volume with new configs.
<br>
<br>         $ sudo -n bless  --mount / --setBoot --nextonly --options "config=boot"
<br>
<br>     The `--nextonly` flag specifies that use the `boot.plist` configs only for one boot.
<br>     So if the kernel panic's you can easily power reboot and recover back to original kernel.
<br>
<br>
<br>
<br>
<br>Creating tags and cscope
<br>========================
<br>
<br>Set up your build environment and from the top directory, run:
<br>
<br>    $ make tags     # this will build ctags and etags on a case-sensitive volume, only ctags on case-insensitive
<br>    $ make TAGS     # this will build etags
<br>    $ make cscope   # this will build cscope database
<br>
<br>
<br>Coding styles (Reindenting files)
<br>=================================
<br>
<br>Source files can be reindented using clang-format setup in .clang-format.
<br>XNU follows a variant of WebKit style for source code formatting.
<br>Please refer to format styles at [WebKit website](http://www.webkit.org/coding/coding-style.html). 
<br>Further options about style options is available at [clang docs](http://clang.llvm.org/docs/ClangFormatStyleOptions.html)
<br>
<br>  Note: clang-format binary may not be part of base installation. It can be compiled from llvm clang sources and is reachable in $PATH.
<br>
<br>  From the top directory, run:
<br>
<br>   $ make reindent      # reindent all source files using clang format.
<br>
<br>
<br>
<br>How to install a new header file from XNU
<br>=========================================
<br>
<br>To install IOKit headers, see additional comments in [iokit/IOKit/Makefile]().
<br>
<br>XNU installs header files at the following locations -
<br>
<br>    a. $(DSTROOT)/System/Library/Frameworks/Kernel.framework/Headers
<br>    b. $(DSTROOT)/System/Library/Frameworks/Kernel.framework/PrivateHeaders
<br>    c. $(DSTROOT)/usr/include/
<br>    d. $(DSTROOT)/System/Library/Frameworks/System.framework/PrivateHeaders
<br>
<br>`Kernel.framework` is used by kernel extensions.\
<br>The `System.framework` and `/usr/include` are used by user level applications. \
<br>The header files in framework's `PrivateHeaders` are only available for ** Apple Internal Development **.
<br>
<br>The directory containing the header file should have a Makefile that
<br>creates the list of files that should be installed at different locations.
<br>If you are adding first header file in a directory, you will need to
<br>create Makefile similar to xnu/bsd/sys/Makefile.
<br>
<br>Add your header file to the correct file list depending on where you want
<br>to install it. The default locations where the header files are installed
<br>from each file list are -
<br>
<br>    a. `DATAFILES` : To make header file available in user level -
<br>       `$(DSTROOT)/usr/include`
<br>
<br>    b. `PRIVATE_DATAFILES` : To make header file available to Apple internal in
<br>       user level -
<br>       `$(DSTROOT)/System/Library/Frameworks/System.framework/PrivateHeaders`
<br>
<br>    c. `KERNELFILES` : To make header file available in kernel level -
<br>       `$(DSTROOT)/System/Library/Frameworks/Kernel.framework/Headers`
<br>       `$(DSTROOT)/System/Library/Frameworks/Kernel.framework/PrivateHeaders`
<br>
<br>    d. `PRIVATE_KERNELFILES` : To make header file available to Apple internal
<br>       for kernel extensions -
<br>       `$(DSTROOT)/System/Library/Frameworks/Kernel.framework/PrivateHeaders`
<br>
<br>The Makefile combines the file lists mentioned above into different
<br>install lists which are used by build system to install the header files.
<br>
<br>If the install list that you are interested does not exist, create it
<br>by adding the appropriate file lists.  The default install lists, its
<br>member file lists and their default location are described below -
<br>
<br>    a. `INSTALL_MI_LIST` : Installs header file to a location that is available to everyone in user level.
<br>        Locations -
<br>           $(DSTROOT)/usr/include
<br>       Definition -
<br>           INSTALL_MI_LIST = ${DATAFILES}
<br>
<br>    b.  `INSTALL_MI_LCL_LIST` : Installs header file to a location that is available
<br>       for Apple internal in user level.
<br>       Locations -
<br>           $(DSTROOT)/System/Library/Frameworks/System.framework/PrivateHeaders
<br>       Definition -
<br>           INSTALL_MI_LCL_LIST = ${PRIVATE_DATAFILES}
<br>
<br>    c. `INSTALL_KF_MI_LIST` : Installs header file to location that is available
<br>       to everyone for kernel extensions.
<br>       Locations -
<br>            $(DSTROOT)/System/Library/Frameworks/Kernel.framework/Headers
<br>       Definition -
<br>            INSTALL_KF_MI_LIST = ${KERNELFILES}
<br>
<br>    d. `INSTALL_KF_MI_LCL_LIST` : Installs header file to location that is
<br>       available for Apple internal for kernel extensions.
<br>       Locations -
<br>            $(DSTROOT)/System/Library/Frameworks/Kernel.framework/PrivateHeaders
<br>       Definition -
<br>            INSTALL_KF_MI_LCL_LIST = ${KERNELFILES} ${PRIVATE_KERNELFILES}
<br>
<br>If you want to install the header file in a sub-directory of the paths
<br>described in (1), specify the directory name using two variables
<br>`INSTALL_MI_DIR` and `EXPORT_MI_DIR` as follows -
<br>
<br>    INSTALL_MI_DIR = dirname
<br>    EXPORT_MI_DIR = dirname
<br>
<br>A single header file can exist at different locations using the steps
<br>mentioned above.  However it might not be desirable to make all the code
<br>in the header file available at all the locations.  For example, you
<br>want to export a function only to kernel level but not user level.
<br>
<br> You can use C language's pre-processor directive (#ifdef, #endif, #ifndef)
<br> to control the text generated before a header file is installed.  The kernel
<br> only includes the code if the conditional macro is TRUE and strips out
<br> code for FALSE conditions from the header file.
<br>
<br> Some pre-defined macros and their descriptions are -
<br>
<br>    a. `PRIVATE` : If true, code is available to all of the xnu kernel and is
<br>       not available in kernel extensions and user level header files.  The
<br>       header files installed in all the paths described above in (1) will not
<br>       have code enclosed within this macro.
<br>
<br>    b. `KERNEL_PRIVATE` : If true, code is available to all of the xnu kernel and Apple
<br>        internal kernel extensions.
<br>
<br>    c. `BSD_KERNEL_PRIVATE` : If true, code is available to the xnu/bsd part of
<br>       the kernel and is not available to rest of the kernel, kernel extensions
<br>       and user level header files.  The header files installed in all the
<br>       paths described above in (1) will not have code enclosed within this macro.
<br>
<br>    d. `KERNEL` :  If true, code is available only in kernel and kernel
<br>       extensions and is not available in user level header files.  Only the
<br>       header files installed in following paths will have the code -
<br>
<br>            $(DSTROOT)/System/Library/Frameworks/Kernel.framework/Headers
<br>            $(DSTROOT)/System/Library/Frameworks/Kernel.framework/PrivateHeaders
<br>
<br>       you should check [Testing the kernel][] for details.
<br>
<br>
<br>How to add a new syscall
<br>========================
<br>
<br>
<br>
<br>
<br>Testing the kernel
<br>==================
<br>
<br>XNU kernel has multiple mechanisms for testing.
<br>
<br>  * Assertions - The DEVELOPMENT and DEBUG kernel configs are compiled with assertions enabled. This allows developers to easily
<br>    test invariants and conditions.
<br>
<br>  * XNU Power On Self Tests (`XNUPOST`): The XNUPOST config allows for building the kernel with basic set of test functions
<br>    that are run before first user space process is launched. Since XNU is hybrid between MACH and BSD, we have two locations where
<br>    tests can be added.
<br>
<br>        xnu/osfmk/tests/     # For testing mach based kernel structures and apis.
<br>        bsd/tests/           # For testing BSD interfaces.
<br>    Please follow the documentation at [osfmk/tests/README.md](osfmk/tests/README.md)
<br>
<br>  * User level tests: The `tools/tests/` directory holds all the tests that verify syscalls and other features of the xnu kernel.
<br>    The make target `xnu_tests` can be used to build all the tests supported.
<br>
<br>        $ make RC_ProjectName=xnu_tests SDKROOT=/path/to/SDK
<br>
<br>    These tests are individual programs that can be run from Terminal and report tests status by means of std posix exit codes (0 -> success) and/or stdout.
<br>    Please read detailed documentation in [tools/tests/unit_tests/README.md](tools/tests/unit_tests/README.md)
<br>
<br>
<br>Kernel data descriptors
<br>=======================
<br>
<br>XNU uses different data formats for passing data in its api. The most standard way is using syscall arguments. But for complex data
<br>it often relies of sending memory saved by C structs. This packaged data transport mechanism is fragile and leads to broken interfaces
<br>between user space programs and kernel apis. `libkdd` directory holds user space library that can parse custom data provided by the
<br>same version of kernel. The kernel chunked data format is described in detail at [libkdd/README.md](libkdd/README.md).
<br>
<br>
<br>Debugging the kernel
<br>====================
<br>
<br>The xnu kernel supports debugging with a remote kernel debugging protocol (kdp). Please refer documentation at [technical note] [TN2063]
<br>By default the kernel is setup to reboot on a panic. To debug a live kernel, the kdp server is setup to listen for UDP connections
<br>over ethernet. For machines without ethernet port, this behavior can be altered with use of kernel boot-args. Following are some
<br>common options.
<br>
<br>  * `debug=0x144` - setups debug variables to start kdp debugserver on panic
<br>  * `-v` - print kernel logs on screen. By default XNU only shows grey screen with boot art.
<br>  * `kdp_match_name=en1` - Override default port selection for kdp. Supported for ethernet, thunderbolt and serial debugging.
<br>
<br>To debug a panic'ed kernel, use llvm debugger (lldb) along with unstripped symbol rich kernel binary.
<br>
<br>    sh$ lldb kernel.development.unstripped
<br>    
<br>And then you can connect to panic'ed machine with `kdp_remote [ip addr]` or `gdb_remote [hostip : port]` commands.
<br>
<br>Each kernel is packaged with kernel specific debug scripts as part of the build process. For security reasons these special commands
<br>and scripts do not get loaded automatically when lldb is connected to machine. Please add the following setting to your `~/.lldbinit`
<br>if you wish to always load these macros.
<br>
<br>    settings set target.load-script-from-symbol-file true
<br>
<br>The `tools/lldbmacros` directory contains the source for each of these commands. Please follow the [README.md](tools/lldbmacros/README.md)
<br>for detailed explanation of commands and their usage.
<br>
<br>[TN2118]: https://developer.apple.com/library/mac/technotes/tn2004/tn2118.html#//apple_ref/doc/uid/DTS10003352 "Kernel Core Dumps"
<br>[TN2063]: https://developer.apple.com/library/mac/technotes/tn2063/_index.html "Understanding and Debugging Kernel Panics"
<br>[Kernel Programming Guide]: https://developer.apple.com/library/mac/documentation/Darwin/Conceptual/KernelProgramming/build/build.html#//apple_ref/doc/uid/TP30000905-CH221-BABDGEGF
<br><p></p><div class="separator"></div><br><p><h2>kmod</h2></p>#
<br># Subtle combination of files and libraries make up the C++ runtime system for
<br># kernel modules.  We are dependant on the KernelModule kmod.make and
<br># CreateKModInfo.perl scripts to be exactly instep with both this library
<br># module and the libkmod module as well.
<br>#
<br># If you do any maintenance on any of the following files make sure great
<br># care is taken to keep them in Sync.
<br>#    extenTools/KernelModule.bproj/kmod.make
<br>#    extenTools/KernelModule.bproj/CreateKModInfo.perl
<br>#    IOKitUser/kmodc++/pure.c
<br>#    IOKitUser/kmodc++/cplus_start.c
<br>#    IOKitUser/kmodc++/cplus_start.c
<br>#    IOKitUser/kmodc/c_start.c
<br>#    IOKitUser/kmodc/c_stop.c
<br>#
<br># The trick is that the linkline links all of the developers modules.
<br># If any static constructors are used .constructors_used will be left as
<br># an undefined symbol.  This symbol is exported by the cplus_start.c routine
<br># which automatically brings in the appropriate C++ _start routine.  However
<br># the actual _start symbol is only required by the kmod_info structure that
<br># is created and initialized by the CreateKModInfo.perl script.  If no C++
<br># was used the _start will be an undefined symbol that is finally satisfied
<br># by the c_start module in the kmod library.
<br># 
<br># The linkline must look like this.
<br>#    *.o -lkmodc++ kmod_info.o -lkmod
<br>#
<br><p></p><div class="separator"></div><br><p><h2>zlib</h2></p>ZLIB DATA COMPRESSION LIBRARY
<br>
<br>zlib 1.2.3 is a general purpose data compression library.  All the code is
<br>thread safe.  The data format used by the zlib library is described by RFCs
<br>(Request for Comments) 1950 to 1952 in the files
<br>http://www.ietf.org/rfc/rfc1950.txt (zlib format), rfc1951.txt (deflate format)
<br>and rfc1952.txt (gzip format). These documents are also available in other
<br>formats from ftp://ftp.uu.net/graphics/png/documents/zlib/zdoc-index.html
<br>
<br>All functions of the compression library are documented in the file zlib.h
<br>(volunteer to write man pages welcome, contact zlib@gzip.org). A usage example
<br>of the library is given in the file example.c which also tests that the library
<br>is working correctly. Another example is given in the file minigzip.c. The
<br>compression library itself is composed of all source files except example.c and
<br>minigzip.c.
<br>
<br>To compile all files and run the test program, follow the instructions given at
<br>the top of Makefile. In short "make test; make install" should work for most
<br>machines. For Unix: "./configure; make test; make install". For MSDOS, use one
<br>of the special makefiles such as Makefile.msc. For VMS, use make_vms.com.
<br>
<br>Questions about zlib should be sent to <zlib@gzip.org>, or to Gilles Vollant
<br><info@winimage.com> for the Windows DLL version. The zlib home page is
<br>http://www.zlib.org or http://www.gzip.org/zlib/ Before reporting a problem,
<br>please check this site to verify that you have the latest version of zlib;
<br>otherwise get the latest version and check whether the problem still exists or
<br>not.
<br>
<br>PLEASE read the zlib FAQ http://www.gzip.org/zlib/zlib_faq.html before asking
<br>for help.
<br>
<br>Mark Nelson <markn@ieee.org> wrote an article about zlib for the Jan. 1997
<br>issue of  Dr. Dobb's Journal; a copy of the article is available in
<br>http://dogma.net/markn/articles/zlibtool/zlibtool.htm
<br>
<br>The changes made in version 1.2.3 are documented in the file ChangeLog.
<br>
<br>Unsupported third party contributions are provided in directory "contrib".
<br>
<br>A Java implementation of zlib is available in the Java Development Kit
<br>http://java.sun.com/j2se/1.4.2/docs/api/java/util/zip/package-summary.html
<br>See the zlib home page http://www.zlib.org for details.
<br>
<br>A Perl interface to zlib written by Paul Marquess <pmqs@cpan.org> is in the
<br>CPAN (Comprehensive Perl Archive Network) sites
<br>http://www.cpan.org/modules/by-module/Compress/
<br>
<br>A Python interface to zlib written by A.M. Kuchling <amk@amk.ca> is
<br>available in Python 1.5 and later versions, see
<br>http://www.python.org/doc/lib/module-zlib.html
<br>
<br>A zlib binding for TCL written by Andreas Kupries <a.kupries@westend.com> is
<br>availlable at http://www.oche.de/~akupries/soft/trf/trf_zip.html
<br>
<br>An experimental package to read and write files in .zip format, written on top
<br>of zlib by Gilles Vollant <info@winimage.com>, is available in the
<br>contrib/minizip directory of zlib.
<br>
<br>
<br>Notes for some targets:
<br>
<br>- For Windows DLL versions, please see win32/DLL_FAQ.txt
<br>
<br>- For 64-bit Irix, deflate.c must be compiled without any optimization. With
<br>  -O, one libpng test fails. The test works in 32 bit mode (with the -n32
<br>  compiler flag). The compiler bug has been reported to SGI.
<br>
<br>- zlib doesn't work with gcc 2.6.3 on a DEC 3000/300LX under OSF/1 2.1 it works
<br>  when compiled with cc.
<br>
<br>- On Digital Unix 4.0D (formely OSF/1) on AlphaServer, the cc option -std1 is
<br>  necessary to get gzprintf working correctly. This is done by configure.
<br>
<br>- zlib doesn't work on HP-UX 9.05 with some versions of /bin/cc. It works with
<br>  other compilers. Use "make test" to check your compiler.
<br>
<br>- gzdopen is not supported on RISCOS, BEOS and by some Mac compilers.
<br>
<br>- For PalmOs, see http://palmzlib.sourceforge.net/
<br>
<br>- When building a shared, i.e. dynamic library on Mac OS X, the library must be
<br>  installed before testing (do "make install" before "make test"), since the
<br>  library location is specified in the library.
<br>
<br>
<br>Acknowledgments:
<br>
<br>  The deflate format used by zlib was defined by Phil Katz. The deflate
<br>  and zlib specifications were written by L. Peter Deutsch. Thanks to all the
<br>  people who reported problems and suggested various improvements in zlib;
<br>  they are too numerous to cite here.
<br>
<br>Copyright notice:
<br>
<br> (C) 1995-2004 Jean-loup Gailly and Mark Adler
<br>
<br>  This software is provided 'as-is', without any express or implied
<br>  warranty.  In no event will the authors be held liable for any damages
<br>  arising from the use of this software.
<br>
<br>  Permission is granted to anyone to use this software for any purpose,
<br>  including commercial applications, and to alter it and redistribute it
<br>  freely, subject to the following restrictions:
<br>
<br>  1. The origin of this software must not be misrepresented; you must not
<br>     claim that you wrote the original software. If you use this software
<br>     in a product, an acknowledgment in the product documentation would be
<br>     appreciated but is not required.
<br>  2. Altered source versions must be plainly marked as such, and must not be
<br>     misrepresented as being the original software.
<br>  3. This notice may not be removed or altered from any source distribution.
<br>
<br>  Jean-loup Gailly        Mark Adler
<br>  jloup@gzip.org          madler@alumni.caltech.edu
<br>
<br>If you use the zlib library in a product, we would appreciate *not*
<br>receiving lengthy legal documents to sign. The sources are provided
<br>for free but without warranty of any kind.  The library has been
<br>entirely written by Jean-loup Gailly and Mark Adler; it does not
<br>include third-party code.
<br>
<br>If you redistribute modified sources, we would appreciate that you include
<br>in the file ChangeLog history information documenting your changes. Please
<br>read the FAQ for more information on the distribution of modified source
<br>versions.
<br><p></p><div class="separator"></div><br><p><h2>devfs</h2></p>Note: The following comments are from the original FreeBSD 3.1 README
<br>
<br>this file is: /sys/miscfs/devfs/README
<br>
<br>to enable: add
<br>options	DEVFS
<br>
<br>to your config file..
<br>expect it to be highly useless for a while,
<br>as the only devices that register themselves are the floppy,
<br>the pcaudio stuff, speaker, null,mem,zero,io,kmem.
<br>
<br>it works like this:
<br>
<br>There is a tree of nodes that describe the layout of the DEVFS as seen by
<br>the drivers.. they add nodes to this tree. This is called the 'back' layer
<br>for reasons that will become obvious in a second. Think of it as a
<br>BLUEPRINT of the DEVFS tree. Each back node has associated with it 
<br>a "devnode" struct, that holds information about the device
<br>(or directory) and a pointer to the vnode if one has been associated 
<br>with that node. The back node itself can be considered to be 
<br>a directory entry, and contains the default name of the device,
<br>and a link to the directory that holds it. It is sometimes refered
<br>to in the code as the dev_name. The devnode can be considered the inode.
<br>
<br>When you mount the devfs somewhere (you can mount it multiple times in
<br>multiple places), a front layer is created that contains a tree of 'front'
<br>nodes.
<br>
<br>Think of this as a Transparency, layed over the top of the blueprint.
<br>(or possibly a photocopy).
<br>
<br>The front and back nodes are identical in type, but the back nodes
<br>are reserved for kernel use only, and are protected from the user.
<br>The back plane has a mount structure and all that stuff, but it is in
<br>fact not really mounted. (and is thus not reachable via namei).
<br>Internal kernel routines can open devices in this plane
<br>even if the external devfs has not been mounted yet :)
<br>(e.g. to find the root device)
<br>
<br>To start with there is a 1:1 relationship between the front nodes
<br>and the backing nodes, however once the front plane has been created
<br>the nodes can be moved around within that plane (or deleted).
<br>Think of this as the ability to revise a transparency...
<br>the blueprint is untouched.
<br>
<br>There is a "devnode" struct associated with each front note also.
<br>Front nodes that refer to devices, use the same "devnode" struct that is used 
<br>by their associated backing node, so that multiple front nodes that
<br>point to the same device will use the same "devnode" struct, and through
<br>that, the same vnode, ops, modification times, flags, owner and group.
<br>Front nodes representing directories and symlinks have their own
<br>"devnode" structs, and may therefore differ. (have different vnodes)
<br>i.e. if you have two devfs trees mounted, you can change the 
<br>directories in one without changing the other. 
<br>e.g. remove or rename nodes
<br>
<br>Multiple mountings are like multiple transparencies,
<br>each showing through to the original blueprint.
<br>
<br>Information that is to be shared between these mounts is stored
<br>in the 'backing' node for that object.  Once you have erased 'front'
<br>object, there is no memory of where the backing object was, and
<br>except for the possibility of searching the entire backing tree
<br>for the node with the correct major/minor/type, I don't see that
<br>it is easily recovered.. Particularly as there will eventually be
<br>(I hope) devices that go direct from the backing node to the driver
<br>without going via the cdevsw table.. they may not even have
<br>major/minor numbers.
<br>
<br>I see 'mount -u' as a possible solution to recovering a broken dev tree.
<br>(though umount+mount would do the same)
<br>
<br>Because non device nodes (directories and symlinks) have their own
<br>"devnode" structs on each layer, these may have different
<br>flags, owners, and contents on each layer.
<br>e.g. if you have a chroot tree like erf.tfs.com has, you
<br>may want different permissions or owners on the chroot mount of the DEVFS
<br>than you want in the real one. You might also want to delete some sensitive
<br>devices from the chroot tree.
<br>
<br>Directories also have backing nodes but there is nothing to stop
<br>the user from removing a front node from the directory front node.
<br>(except permissions of course).  This is because the front directory
<br>nodes keep their own records as to which front nodes are members
<br>of that directory and do not refer to their original backing node
<br>for this information.
<br>
<br>The front nodes may be moved to other directories (including
<br>directories) however this does not break the linkage between the
<br>backing nodes and the front nodes. The backing node never moves. If
<br>a driver decides to remove a device from the backing tree, the FS
<br>code follows the links to all the front nodes linked to that backing
<br>node, and deletes them, no matter where they've been moved to.
<br>(active vnodes are redirected to point to the deadfs).
<br>
<br>If a directory has been moved, and a new backing node is inserted
<br>into its own back node, the new front node will appear in that front
<br>directory, even though it's been moved, because the directory that
<br>gets the front node is found via the links and not by name.
<br>
<br>a mount -u might be considered to be a request to 'refresh' the
<br>plane that controls to the mount being updated.. that would have the
<br>effect of 're-propogating' through any backing nodes that find they
<br>have no front nodes in that plane.
<br>
<br>
<br>NOTES FOR RELEASE 1.2
<br>1/ this is very preliminary
<br>2/ the routines have greatly simplified since release 1.1
<br>(I guess the break did me good :)
<br>3/ many features are not present yet..
<br>e.g. symlinks, a comprehensive registration interface (only a crude one)
<br>ability to unlink and mv nodes.
<br>4/ I'm pretty sure my use of vnodes is bad and it may be 'losing'
<br>them, or alternatively, corrupting things.. I need a vnode specialist
<br>to look at this.
<br>
<br><p></p><div class="separator"></div><br><p><h2>libkdd</h2></p>Kernel Data Descriptors
<br>=======================
<br>
<br>This project allows for dynamic data to be passed from the kernel to userspace tools without binding them to particular version of
<br>struct definition. The `libkdd` library provides convenient API for parsing and interpreting `kernel chunked data`.
<br>
<br>The libkdd APIs are defined in [kdd.h](./kdd.h)
<br>
<br>The `KCDATA` format
<br>===================
<br>
<br>The format for data is setup in a generic format as follows
<br>
<br>Layout of data structure
<br>------------------------
<br>
<br>	|         8 - bytes         |
<br>	|---------------------------|  ------ offset = 00
<br>	|  type = MAGIC |  LENGTH   |  # BEGIN Header
<br>	|            0              |
<br>	|---------------------------|  ------ offset = 16
<br>	|      type     |  size     |  # chunk header
<br>	|          flags            |
<br>	|---------------------------|  ------ offset = 32
<br>	|           data            |  # arbitrary data (len=16)
<br>	|___________data____________|
<br>	|---------------------------|  ------ offset = 48
<br>	|      type     |   size    |  # chunk header
<br>	|          flags            |
<br>	|---------------------------|  ------ offset = 64
<br>	|           data            |  # arbitrary data (len=32)
<br>	|           data            |
<br>	|           data            |
<br>	|___________data____________|
<br>	|---------------------------|  ------ offset = 96
<br>	|  type = END   |  size=0   |  # chunk header
<br>	|            0              |
<br>
<br>
<br>The type field describes what kind of data is passed. For example type = `TASK_CRASHINFO_UUID` means the following data is a uuid.
<br>These types need to be defined in task_corpses.h for easy consumption by userspace inspection tools.
<br>
<br>Some range of types is reserved for special types like ints, longs etc. A cool new functionality made possible with this
<br>extensible data format is that kernel can decide to put more information as required without requiring user space tools to
<br>re-compile to be compatible. The case of `rusage` struct versions could be introduced without breaking existing tools.
<br>
<br>Feature description: Generic data with description
<br>-------------------
<br>Further more generic data with description is very much possible now. For example
<br>
<br>	- kcdata_add_uint64_with_description(cdatainfo, 0x700, "NUM MACH PORTS");
<br>	- and more functions that allow adding description.
<br>
<br>The userspace tools can then look at the description and print the data even if they are not compiled with knowledge of the field apriori.
<br>
<br>	Example data:
<br>	0000  57 f1 ad de 00 00 00 00 00 00 00 00 00 00 00 00  W...............
<br>	0010  01 00 00 00 00 00 00 00 30 00 00 00 00 00 00 00  ........0.......
<br>	0020  50 49 44 00 00 00 00 00 00 00 00 00 00 00 00 00  PID.............
<br>	0030  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
<br>	0040  9c 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
<br>	0050  01 00 00 00 00 00 00 00 30 00 00 00 00 00 00 00  ........0.......
<br>	0060  50 41 52 45 4e 54 20 50 49 44 00 00 00 00 00 00  PARENT PID......
<br>	0070  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
<br>	0080  01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
<br>	0090  ed 58 91 f1
<br>
<br>
<br>Feature description: Container markers for compound data
<br>------------------
<br>
<br>If a given kernel data type is complex and requires adding multiple optional fields inside a container
<br>object for a consumer to understand arbitrary data, we package it using container markers.
<br>
<br>For example, the stackshot code gathers information and describes the state of a given task with respect
<br>to many subsystems. It includes data such as io stats, vm counters, process names/flags and syscall counts.
<br>
<br>	kcdata_add_container_marker(kcdata_p, KCDATA_TYPE_CONTAINER_BEGIN, STACKSHOT_KCCONTAINER_TASK, task_uniqueid);
<br>	// add multiple data, or add_<type>_with_description()s here
<br>
<br>	kcdata_add_container_marker(kcdata_p, KCDATA_TYPE_CONTAINER_END, STACKSHOT_KCCONTAINER_TASK, task_uniqueid);
<br>
<br>
<br>Feature description: Custom Data formats on demand
<br>--------------------
<br>
<br>With the self describing nature of format, the kernel provider can describe a data type (uniquely identified by a number) and use
<br>it in the buffer for sending data. The consumer can parse the type information and have knowledge of describing incoming data.
<br>Following is an example of how we can describe a kernel specific struct sample_disk_io_stats in buffer.
<br>
<br>	struct sample_disk_io_stats {
<br>	    uint64_t        disk_reads_count;
<br>	    uint64_t        disk_reads_size;
<br>	    uint64_t        io_priority_count[4];
<br>	    uint64_t        io_priority_size;
<br>	} __attribute__ ((packed));
<br>
<br>
<br>	struct kcdata_subtype_descriptor disk_io_stats_def[] = {
<br>	    {KCS_SUBTYPE_FLAGS_NONE, KC_ST_UINT64, 0 * sizeof(uint64_t), sizeof(uint64_t), "disk_reads_count"},
<br>	    {KCS_SUBTYPE_FLAGS_NONE, KC_ST_UINT64, 1 * sizeof(uint64_t), sizeof(uint64_t), "disk_reads_size"},
<br>	    {KCS_SUBTYPE_FLAGS_ARRAY, KC_ST_UINT64, 2 * sizeof(uint64_t), KCS_SUBTYPE_PACK_SIZE(4, sizeof(uint64_t)), "io_priority_count"},
<br>	    {KCS_SUBTYPE_FLAGS_ARRAY, KC_ST_UINT64, (2 + 4) * sizeof(uint64_t), sizeof(uint64_t), "io_priority_size"},
<br>	};
<br>
<br>Now you can add this custom type definition into the buffer as
<br>	kcdata_add_type_definition(kcdata_p, KCTYPE_SAMPLE_DISK_IO_STATS, "sample_disk_io_stats",
<br>	         &disk_io_stats_def[0], sizeof(disk_io_stats_def)/sizeof(struct kcdata_subtype_descriptor));
<br>
<br><p></p><div class="separator"></div><br><p><h2>config</h2></p>This directory contains a universal DEBUG kernel, built for 32-bit and
<br>64-bit Intel. It includes a dSYM bundle for remote kernel debugging
<br>and live kernel debugging.
<br>
<br>INSTALLATION
<br>
<br>!!!WARNING!!! These steps will overwrite the default kernel and
<br>System.kext. Backup all files before attempting these steps.
<br>
<br>To install the DEBUG kernel, do:
<br>bash-3.2$ sudo -s
<br>bash-3.2# cd /
<br>bash-3.2# ditto /AppleInternal/Developer/Extras/Kernel\ Debugging/System.kext /System/Library/Extensions/System.kext
<br>bash-3.2# cp -r /AppleInternal/Developer/Extras/Kernel\ Debugging/mach_kernel* /
<br>bash-3.2# chown -R root:wheel /System/Library/Extensions/System.kext /mach_kernel*
<br>bash-3.2# chmod -R g-w /System/Library/Extensions/System.kext /mach_kernel*
<br>bash-3.2# touch /System/Library/Extensions
<br>bash-3.2# shutdown -r now
<br>
<br>REMOTE KERNEL DEBUGGING
<br>
<br>See the documentation that accompanies the Kernel Debug Kit
<br>
<br>LIVE KERNEL DEBUGGING
<br>
<br>With the DEBUG kernel installed, set "kmem=1" in your "boot-args"
<br>NVRAM variable, reboot, and do:
<br>
<br>bash-3.2$ sudo gdb -a <arch> --quiet /mach_kernel
<br>(gdb) target darwin-kernel
<br>(gdb) source /AppleInternal/Developer/Extras/Kernel\ Debugging/kgmacros
<br>Loading Kernel GDB Macros package.  Type "help kgm" for more info.
<br>(gdb) attach
<br>Connected.
<br>
<br><arch> should reflect the currently booted kernel architecture, either
<br>"i386" or "x86_64"
<br>
<br>
<br><p></p><div class="separator"></div><br><p><h2>lldbmacros</h2></p>Table of Contents
<br>=================
<br>
<br>      A. How to use lldb for kernel debugging
<br>      B. Design of lldb kernel debugging platform.
<br>      C. Kernel debugging commands.
<br>          i. Using commands.
<br>         ii. Writing new commands.
<br>      D. Kernel type summaries.
<br>          i. Using summaries
<br>         ii. Writing new summary functions
<br>      E. FAQ and General Coding Guidelines
<br>          i. Frequently Asked Questions
<br>         ii. Formatted Output printing guidelines [MUST READ]
<br>        iii. Coding conventions.  [MUST READ]
<br>         iv. Submitting changes in lldbmacros [MUST READ]
<br>          v. Common utility functions and paradigms
<br>      F. Development and Debugging on lldb kernel debugging platform.
<br>          i. Reading a exception backtrace
<br>         ii. Loading custom or local lldbmacros and operating_system plugin
<br>        iii. Adding debug related 'printf's
<br>
<br>A. How to use lldb for kernel debugging
<br>========================================
<br>
<br>lldb can be used for kernel debugging the same way as gdb. The simplest way is to start lldb with kernel symbol file. The lldb environment by default does not allow loading automatic python modules. Please add the following setting in
<br>
<br>    File: ~/.lldbinit
<br>    settings set target.load-script-from-symbol-file true
<br>
<br>Now lldb will be ready to connect over kdp-remote '\<hostname:port>' or 'gdb-remote \<hostname:port>'. In case using a core file please do 'file --core /path/to/corefile'
<br>
<br>Following are detailed steps on how to debug a panic'ed / NMI'ed machine (For the curious souls).
<br>
<br>lldb debugging in detail:-
<br>
<br>  * start lldb with the right symbols file. If you do not know the version apriori, then enable dsymForUUID to load symbols dynamically.
<br>        bash$ dsymForUUID --enable
<br>        bash$ lldb /path/to/mach_kernel.symbols
<br>        Current executable set to '/Sources/Symbols/xnu/xnu-2253~2/mach_kernel' (x86_64).
<br>        (lldb)
<br>
<br>  * connect to remote device or load a core file
<br>        #for kdp
<br>        (lldb) process connect --plugin kdp-remote udp://17.123.45.67:41139
<br>        #for gdb (eg with astris)
<br>        (lldb) process connect --plugin gdb-remote gdb://17.123.45.67:8000
<br>        #for loading a core file
<br>        (lldb) file --core /path/to/core/file  /path/to/kernel_symbol_file
<br>
<br>  * Once connected you can debug with basic lldb commands like print, bt, expr etc. The xnu debug macros will also be loaded automatically from the dSYM files.
<br>  In case if you are working with older kernel files you can load kernel specific commands by doing -
<br>        (lldb) command script import /path/to/xnu/tools/lldbmacros/xnu.py
<br>        (lldb) showbootargs
<br>        debug=0x14e ncpus=2
<br>
<br>  * You can do `kgmhelp` to get a list of commands available through xnu.py
<br>
<br>SPECIAL: The `xnu.py` script brings in kernel type summary functions. To enable these please do -
<br>
<br>    (lldb) showlldbtypesummaries
<br>
<br>These could be very handy in printing important information from structures easily.
<br>For ex.
<br>
<br>    (lldb) print (thread_t)0x80d6a620
<br>    (thread_t) $45 = 0x80d6a620
<br>    thread                   thread_id  processor            pri    io_policy  state wait_queue           wait_event           wmesg                thread_name
<br>    0x80d6a620               0x317      0x902078c8           61                W     0x910cadd4           0x0                                       SystemSoundServer
<br>
<br>
<br>
<br>B. Design of lldb kernel debugging platform.
<br>=============================================
<br>
<br>The lldb debugger provides python scripting bridge for customizing commands and summaries in lldb. Following is the stack of platforms and how commands and summaries interact with it.
<br>
<br>    |------- xnu scripts ----------|
<br>    | |- lldb Command/Scripting-|  |   <-- provides scriptability for kernel data structures through summary/command invocation.
<br>    | |    |--lldb core--|      |  |   <-- interacts with remote kernel or corefile.
<br>    | |-------------------------|  |
<br>    |------------------------------|
<br>
<br>The xnu script in xnu/tools/lldbmacros provides the following:
<br>
<br>  * Custom functions to do plumbing of lldb command invocation to python function call. (see doc strings for @lldb_command)
<br>    The command interface provides some common features (which can be invoked after passing '--' on cmd line) like -
<br>
<br>      i. send the output of command to file on disk
<br>      ii. search for a string in the output and selectively print the line containing it.
<br>      iii. -v options to increase verbosity levels in commands.
<br>        For example: (lldb)showalltasks -- -s kernel_task --o /tmp/kernel_task.output -v
<br>        will show task summary output with lines matching string 'kernel_task' into a file /tmp/kernel_task.output and with a verbosity level of (default +1)
<br>
<br>  * Customization for plugging in summary functions for lldb type summaries. (see doc strings for @lldb_summary)
<br>     It will automatically register given types with the functions within the kernel category.
<br>
<br>  * Ability to register test cases for macros (see doc strings for @xnudebug_test).
<br>
<br>The file layout is like following
<br>
<br>    xnu/
<br>     |-tools/
<br>       |-lldbmacros/
<br>         |-core/       # Core logic about kernel, lldb value abstraction, configs etc. **DO NOT TOUCH THIS DIR**
<br>         |-plugins/    # Holds plugins for kernel commands.
<br>         |-xnu.py      # xnu debug framework along with kgmhelp, xnudebug commands.
<br>         |-xnudefines.py
<br>         |-utils.py
<br>         |-process.py  # files containing commands/summaries code for each subsystem
<br>         |-...
<br>
<br>
<br>The lldbmacros directory has a Makefile that follows the build process for xnu. This packages lldbmacros scripts into the dSYM of each kernel build. This helps in rev-locking the lldb commands with changes in kernel sources.
<br>
<br>
<br>C. Kernel debugging commands.
<br>==============================
<br>i. Using commands.
<br>------------------
<br>Using xnu debug commands is very similar to kgmacros in gdb. You can use 'kgmhelp' to get a listing of available commands.
<br>If you need detailed help for a command please type 'help <command name>' and the documentation for the command will be displayed.
<br>For ex.
<br>
<br>    (lldb) help pmap_walk
<br>    Perform a page-table walk in <pmap> for <virtual_address>.
<br>         You can pass -- -v for verbose output. To increase the verbosity add more -v args after the '--'.
<br>    Syntax: pmap_walk <pmap> <virtual_address>
<br>
<br>The basic format for every command provided under kgmhelp is like follows
<br>
<br>    (lldb) command_name [cmd_args..] [-CMDOPTIONS] [-xnuoptions]
<br>    where:
<br>      command_name : name of command as registed using the @lldb_command decorator and described in 'kgmhelp'
<br>      cmd_args     : shell like arguments that are passed as is to the registered python function.
<br>                     If there is error in these arguments than the implementor may display according error message.
<br>      xnuoptions   : common options for stream based operations on the output of command_name.
<br>                     Allowed options are
<br>                     -h          : show help string of a command
<br>                     -s <regexp> : print only the lines matching <regexp>
<br>                     -o <file>   : direct the output of command to <file>. Will not display anything on terminal
<br>                     -v          : increase the verbosity of the command. Each '-v' encountered will increase verbosity by 1.
<br>                     -p <plugin> : pass the output of command to <plugin> for processing and followup with command requests by it.
<br>      CMDOPTIONS   : These are command level options (always a CAPITAL letter option) that are defined by the macro developer. Please do
<br>                     help <cmdname> to know how each option operates on that particular command. For an example of how to use CMDOPTIONS, take a look at vm_object_walk_pages in memory.py
<br>
<br>ii. Writing new commands.
<br>--------------------------
<br>The python modules are designed in such a way that the command from lldb invokes a python function with the arguments passed at lldb prompt.
<br>
<br>It is recommended that you do a decoupled development for command interface and core utility function so that any function/code can be called as a simple util function and get the same output. i.e.
<br>
<br>    (lldb)showtask 0xabcdef000 is same as python >>> GetTaskSummary(0xabcdef000) or equivalent
<br>
<br>Following is a step by step guideline on how to add a new command ( e.g showtaskvme ). [extra tip: Always good idea to wrap your macro code within # Macro: , # EndMacro.]
<br>
<br>  1. register a command to a function. Use the lldb_command decorator to map a 'command_name' to a function. Optionally you can provide getopt compatible option string for customizing your command invocation. Note: Only CAPITAL letter options are allowed. lowercase options are reserved for the framework level features.
<br>
<br>  2. Immediately after the register define the function to handle the command invocation. The signature is always like Abc(cmd_args=None, cmd_options={})
<br>
<br>  3. Add documentation for Abc(). This is very important for lldb to show help for each command. [ Follow the guidelines above with documentation ]
<br>
<br>  4. Use cmd_args array to get args passed on command. For example a command like `showtaskvme 0xabcdef00` will put have cmd_args=['0xabcdef00']
<br>      - note that we use core.value class as an interface to underlying C structures. Refer [Section B] for more details.
<br>      - use kern.globals.\<variable_name> & kern.GetValueFromAddress for building values from addresses.
<br>      - remember that the ideal type of object to be passed around is core.value
<br>      - Anything you 'print' will be relayed to lldb terminal output.
<br>
<br>  5. If the user has passed any custom options they would be in cmd_options dict. the format is `{'-<optionflag>':'<value>'}`. The \<value> will be '' (empty string) for non-option flags.
<br>
<br>  6. If your function finds issue with the passed argument then you can `raise ArgumentError('error_message')` to notify the user. The framework will automatically catch this and show appropriate help using the function doc string.
<br>
<br> Time for some code example? Try reading the code for function ShowTaskVmeHelper in memory.py.
<br>
<br>SPECIAL Note: Very often you will find yourself making changes to a file for some command/summary and would like to test it out in lldb.
<br>
<br>To easily reload your changes in lldb please follow the below example.
<br>
<br>  * you fire up lldb and start using zprint. And soon you need to add functionality to zprint.
<br>
<br>  * you happily change a function code in memory.py file to zprint macro.
<br>
<br>  * now to reload that particular changes without killing your debug session do
<br>        (lldb) xnudebug reload memory
<br>         memory is reloaded from ./memory.py
<br>        (lldb)
<br>
<br>  * Alternatively, you can use lldb`s command for script loading as
<br>        (lldb) command script import /path/to/memory.py
<br>    You can re-run the same command every time you update the code in file.
<br>
<br> It is very important that you do reload using xnudebug command as it does the plumbing of commands and types for your change in the module. Otherwise you could easily get confused
<br> why your changes are not reflected in the command.
<br>
<br>
<br>D. Kernel type summaries.
<br>==========================
<br>i. Using summaries
<br>------------------
<br>The lldb debugger provides ways for user to customize how a particular type of object be decsribed when printed. These are very useful in displaying complex and large structures
<br>where only certain fields are important based on some flag or value in some field or variable. The way it works is every time lldb wants to print an object it checks
<br>for registered summaries. We can define python functions and hook it up with lldb as callbacks for type summaries.  For example.
<br>
<br>    (lldb) print first_zone
<br>    (zone_t) $49 = 0xd007c000
<br>          ZONE            TOT_SZ ALLOC_ELTS  FREE_ELTS    FREE_SZ ELT_SZ  ALLOC(ELTS  PGS  SLK)     FLAGS      NAME
<br>    0x00000000d007c000      29808        182         25       3600    144   4096   28    1   64   X$          zones
<br>    (lldb)
<br>Just printing the value of first_zone as (zone_t) 0xd007c000 wouldnt have been much help. But with the registered summary for zone_t we can see all the interesting info easily.
<br>
<br>You do not need to do anything special to use summaries. Once they are registered with lldb they show info automatically when printing objects. However if you wish to
<br>see all the registered type summaries run the command `type summary list -w kernel` on lldb prompt.
<br>Also if you wish to quickly disable the summaries for a particular command use the `showraw` command.
<br>
<br>ii. Writing new summary functions
<br>---------------------------------
<br>lldb provides really flexible interface for building summaries for complex objects and data. If you find that a struct or list can be
<br>diagnosed better if displayed differently, then feel free to add a type summary for that type. Following is an easy guide on how to do that.
<br>
<br>  1. Register a function as a callback for displaying information for a type. Use the `@lldb_type_summary()` decorator with an array of types you wish to register for callback
<br>
<br>  2. Provide a header for the summary using `@header()` decorator. This is a strong requirement for summaries. This gets displayed before the output
<br>     of `GetTypeSummary()` is displayed. [In case you do not wish to have header then still define it as "" (empty string) ]
<br>
<br>  3. Define the function with signature of `GetSomeTypeSummary(valobj)`. It is highly recommended that the naming be consistent to `Get.*?Summary(valobj)`
<br>     The valobj argument holds the core.value object for display.
<br>
<br>  4. Use the utility functions and memory read operations to pull out the required information.
<br>     [ use `kern.globals` & `kern.GetValueFromAddress` for building args to core functions. ]
<br>     [ remember that the ideal type of object to be passed around is core.value ]
<br>
<br>  5. return a string that would be printed by the caller. When lldb makes a call back it expects a str to be returned. So do not print
<br>     directly out to console. [ debug info or logs output is okay to be printed anywhere :) ]
<br>
<br>Time for some code example? Try reading the code for GetTaskSummary() in process.py.
<br>
<br>
<br>
<br>E. FAQs and Generel Coding Guidelines
<br>======================================
<br>
<br>i. Frequently Asked Questions
<br>-----------------------------
<br>
<br>  Q. How do I avoid printing the summary and see the actual data in a structure?
<br>
<br>  A. There is a command called `showraw`. This will disable all kernel specific type summaries and execute any command you provide. For ex.
<br>
<br>    (lldb) print (thread_t) 0x80d6a620
<br>    (thread_t) $45 = 0x80d6a620
<br>    thread                   thread_id  processor            pri    io_policy  state wait_queue           wait_event           wmesg                thread_name
<br>    0x80d6a620               0x317      0x902078c8           61                W     0x910cadd4           0x0                                       SystemSoundServer
<br>    (lldb) showraw print (thread_t) 0x80d6a620
<br>    (thread_t) $48 = 0x80d6a620
<br>
<br>  Q. I typed `showallvnodes` and nothing happens for a long time? OR How do I get output of long running command instantly on the terminal?
<br>
<br>  A. The lldb command interface tries to build result object from output of a python function. So in case of functions with very long output or runtime it may
<br>     seem that the lldb process is hung. But it is not. You can use "-i" option to get immediate output on terminal.
<br>
<br>        ex. (lldb) showallvnodes -- -i
<br>         Immediate Output
<br>         ....
<br>
<br>  Q. I made a change in a python file for a command or summary, but the output is not reflected in the lldb command?
<br>
<br>  A. The python framework does not allow for removing a loaded module and then reloading it. So sometimes if a command has a cached value from
<br>     old code that it will still call the old function and hence will not display new changes in file on disk. If you find yourself in such a situation
<br>     please see [Section C. -> SPECIAL Note]. If the change is to basic class or caching mechanism than it is advised to quit lldb and re-load all modules again.
<br>
<br>  Q. I am new to python. I get an error message that I do not understand. what should I do?
<br>
<br>  A. The syntax for python is different from conventional programming languages. If you get any message with SyntaxError or TypeError or ValueError then please review your code and look for common errors like
<br>
<br>  - wrong level of indentation?
<br>  - missed a ':' at the end of an if, elif, for, while statement?
<br>  - referencing a key in dictionary that doesn't exist? You might see KeyError in such cases.
<br>  - mistakenly used python reserved keyword as variable? (check http://docs.python.org/release/3.0.1/reference/lexical_analysis.html#id8)
<br>  - Trying to modify a string value? You can only create new strings but never modify existing ones.
<br>  - Trying to add a non string value to a string? This typically happens in print "time is " + gettime(). here gettime() returns int and not str.
<br>  - using a local variable with same name as global variable?
<br>  - assigning a value to global variable without declaring first? Its highly recommended to always declare global variable with 'global' keyword
<br>  If you still have difficulty you can look at the python documentation at http://docs.python.org
<br>
<br>
<br>  Q. I wish to pass value of variable/expression to xnu lldb macro that accepts only pointers. How can I achieve that?
<br>
<br>  A. Many lldb macros have syntax that accepts pointers (eg showtaskstacks etc). In order to have your expression be evaluated before passing to command use `back ticks`. For example:
<br>
<br>        (lldb) showtaskstacks  `(task_t)tasks.next`
<br>        This way the expressing withing ` ` is evaluated by lldb and the value is passed to the command.
<br>        Note that if your argument pointer is bad or the memory is corrupted lldb macros will fail with a long backtrace that may not make sense. gdb used to fail silently but lldb does not.
<br>        Please see Section F(i) for more information on reading backtraces.
<br>
<br>  Q. I connected to a coredump file with lldb --core corefile and I got RuntimeError: Unable to find lldb thread for tid=XYZ. What should I do?
<br>
<br>  A. This is most likely the case that lldb ignored the operating system plugin in the dSYM and hence threads are not populated. Please put the line 'settings set target.load-script-from-symbol-file true' in your ~/.lldbinit file. If you do not have access you can alternatively do
<br>
<br>        bash# lldb
<br>        (lldb) settings set target.load-script-from-symbol-file true
<br>        (lldb) file --core corefile
<br>
<br>
<br>ii. Formatted output printing - zen and peace for life
<br>------------------------------------------------------
<br>
<br>To avoid the horrors of printing a tabular data on console and then 2 weeks later again messing with it for a new field, it is recommended to follow these guidelines.
<br>
<br>  * any python string can be invoked to "".format() and hence makes it very easy to play with formats
<br>
<br>  * As a convention, I suggest that for printing pointer values in hex use "{0: <#020x}".format(some_int_value). This will print nice 0x prefixed strings with length padded to 20.
<br>
<br>  * If you need help with format options take a look at http://docs.python.org/library/string.html#format-string-syntax
<br>
<br>  * [ I'd first create a format string for data and then for the header just change the x's and d's to s and pass the header strings to format command. see GetTaskSummary()]
<br>
<br>  * If you need to print a string from a core.value object then use str() to get string representation of value.
<br>
<br>
<br>iii. Coding conventions
<br>-----------------------
<br>It is very very HIGHLY RECOMMENDED to follow these guidelines for writing any python code.
<br>
<br> * Python is very sensitive to tabs and spaces for alignment. So please make sure you **INDENT YOUR CODE WITH SPACES** at all times.
<br>
<br> * The standard tab width is 4 spaces. Each increasing indent adds 4 spaces beginning of the line.
<br>
<br> * The format for documentation is -
<br>        """ A one line summary describing what this function / class does
<br>            Detailed explanation if necessary along with params and return values.
<br>        """
<br>
<br> * All Classes and functions should have a doc string describing what the function does
<br>   A consistent format is expected. For ex.
<br>    def SumOfNumbers(a, b, c, d):
<br>        """ Calculate sum of numbers.
<br>            params:
<br>                a - int, value to be added. can be 0
<br>                b - int/float, value to be added.
<br>            returns:
<br>                int/float - Sum of two values
<br>            raises:
<br>                TypeError - If any type is not identified in the params
<br>        """
<br>
<br> * A Class or Function should always start with CAPITAL letter and be CamelCase. If a function is for internal use only than it starts with '_'.
<br>
<br> * Function params should always be lower_case and be word separated with '_'
<br>
<br> * A local variable inside a function should be lower_case and separated with '_'
<br>
<br> * A variable for internal use in object should start with '_'.
<br>
<br> * if a class variable is supposed to hold non native type of object, it is good idea to comment what type it holds
<br>
<br> * A class function with name matching `Get(.*?)Summary()` is always supposed to return a string which can be printed on stdout or any file.
<br>
<br> * Functions beginning with "Get" (eg. GetVnodePath())  mean they return a value and will not print any output to stdout.
<br>
<br> * Functions beginning with "Show"  (eg. ShowZTrace()) mean they will print data on screen and may not return any value.
<br>
<br>
<br>iv. Submitting changes in lldbmacros
<br>------------------------------------
<br>
<br>To contribute new commands or fixes to existing one, it is recommended that you follow the procedure below.
<br>
<br>  * Save the changes requried for new command or fix into lldbmacros directory.
<br>
<br>  * Make sure that the coding conventions are strictly followed.
<br>
<br>  * Run syntax checker on each of the modified files. It will find basic formatting errors in the changed files for you.
<br>
<br>  * If you are adding new file then please update the Makefile and xnu.py imports to ensure they get compiled during kernel build.
<br>
<br>  * Do a clean build of kernel from xnu top level directory.
<br>
<br>  * Verify that your changes are present in the dSYM directory of new build.
<br>
<br>  * Re-run all your test and verification steps with the lldbmacros from the newly packaged dSYM/Contents/Resources/Python/lldbmacros.
<br>
<br>v. Common utility functions and paradigms
<br>-----------------------------------------
<br>Please search and look around the code for common util functions and paradigm
<br>
<br>  * Take a peek at utils.py for common utility like sizeof_fmt() to humanize size strings in KB, MB etc. The convention is to have functions that do self contained actions and does not require intricate knowledge of kernel structures in utils.py
<br>
<br>  * If you need to get pagesize of the traget system, do not hard code any value. kern.globals.page_size is your friend. Similarly use config['verbosity'] for finding about configs.
<br>
<br>  * If you are developing a command for structure that is different based on development/release kernels please use "hasattr()" functionality to conditionalize referencing #ifdef'ed fields in structure. See example in def GetTaskSummary(task) in process.py
<br>
<br>
<br>F. Development and Debugging on lldb kernel debugging platform.
<br>===============================================================
<br>
<br>i. Reading a exception backtrace
<br>--------------------------------
<br>In case of an error the lldbmacros may print out an exception backtrace and halt immediately. The backtrace is very verbose and may be confusing. The important thing is to isolate possible causes of failure, and eventually filing a bug with kernel team. Following are some common ways where you may see an exception instead of your expected result.
<br>
<br>  * The lldbmacros cannot divine the type of memory by inspection. If a wrong pointer is passed from commandline then, the command code will try to read and show some results. It may still be junk or plain erronous. Please make sure your command arguments are correct.
<br>    For example: a common mistake is to pass task address to showactstack. In such a case lldb command may fail and show you a confusing backtrace.
<br>
<br> * Kernel debugging is particularly tricky. Many parts of memory may not be readable. There could be failure in network, debugging protocol or just plain bad memory. In such a case please try to see if you can examine memory for the object you are trying to access.
<br>
<br> * In case of memory corruption, the lldbmacros may have followed wrong pointer dereferencing. This might lead to failure and a exception to be thrown.
<br>
<br>
<br>ii. Loading custom or local lldbmacros and operating_system plugin
<br>------------------------------------------------------------------
<br>
<br>The lldbmacros are packaged right into the dSYM for the kernel executable. This makes debugging very easy since they can get loaded automatically when symbols are loaded.
<br>However, this setup makes it difficult for a lldbmacro developer to load custom/local macros. Following is the suggested solution for customizing your debugging setup:
<br>
<br>  * set up environment variable DEBUG_XNU_LLDBMACROS=1 on your shell. This will disable the automatic setup of lldbmacros and the operating_system.py from the symbols.
<br>     - bash$ export DEBUG_XNU_LLDBMACROS=1
<br>
<br>  * start lldb from the shell
<br>     - bash$ lldb
<br>
<br>  * [optional] If you are making changes in the operating_system plugin then you need to set the plugin path for lldb to find your custom operating_system plugin file.
<br>     - (lldb)settings set target.process.python-os-plugin-path /path/to/xnu/tools/lldbmacros/core/operating_system.py
<br>     If you do not wish to change anything in operating_system plugin then just leave the setting empty. The symbol loading module will set one up for you.
<br>
<br>  * Load the xnu debug macros from your custom location.
<br>     - (lldb)command script import /path/to/xnu/tools/lldbmacros/xnu.py
<br>
<br>
<br>iii. Adding debug related 'printf's
<br>-----------------------------------
<br>
<br>The xnu debug framework provides a utility function (debuglog) in utils.py. Please use this for any of your debugging needs. It will not print any output unless the user turns on debug logging on the command. Please check the documentaiton of debuglog for usage and options.
<br>
<br>  * To enable/disable logging
<br>     - (lldb) xnudebug debug
<br>       Enabled debug logging.
<br>
<br>
<br><p></p><div class="separator"></div><br><p><h2>libMicro</h2></p>#
<br># CDDL HEADER START
<br>#
<br># The contents of this file are subject to the terms
<br># of the Common Development and Distribution License
<br># (the "License").  You may not use this file except
<br># in compliance with the License.
<br>#
<br># You can obtain a copy of the license at
<br># src/OPENSOLARIS.LICENSE
<br># or http://www.opensolaris.org/os/licensing.
<br># See the License for the specific language governing
<br># permissions and limitations under the License.
<br>#
<br># When distributing Covered Code, include this CDDL
<br># HEADER in each file and include the License file at
<br># usr/src/OPENSOLARIS.LICENSE.  If applicable,
<br># add the following below this CDDL HEADER, with the
<br># fields enclosed by brackets "[]" replaced with your
<br># own identifying information: Portions Copyright [yyyy]
<br># [name of copyright owner]
<br>#
<br># CDDL HEADER END
<br>#
<br>
<br>#
<br># Copyright 2005 Sun Microsystems, Inc.  All rights reserved.
<br># Use is subject to license terms.
<br>#
<br>
<br>Building the tarball
<br>--------------------
<br>As long as cc is in your path, (gcc on Linux),
<br>
<br>% tar xf libMicro.tar
<br>% make
<br>
<br>will build the benchmark suite.
<br>
<br>Running the benchmarks
<br>-----------------------
<br>
<br>A set of generic scripts to invoke each micro benchmark
<br>are created in the bin directory; these may be invoked
<br>directly.  Note that the actual binaries are created in
<br>OS-specific directories; this allows one to build for
<br>all varients (x86/sparc/Solaris/Linux) in one place.
<br>
<br>To collect a complete set of benchmarks, use the bench
<br>script and redirect its output to a file.
<br>
<br>% ./bench > output
<br>
<br>To compare the output of two or more runs, use multiview in the src
<br>directory:
<br>
<br>% ./multiview reference compare1 compare2 compare2 > compare.html
<br>%
<br>
<br>where the reference and compare files contain the output of different
<br>libmicro runs.
<br>
<br>The compare.html file will allow quick comparisons to be drawn,
<br>allowing a variety of experiments to be quickly analyzed.
<br>
<br>All benchmarks support the following options:
<br>
<br>       [-1] (single process; overrides -P > 1)
<br>       [-A] (align with clock)
<br>       [-B batch-size (default 10)]
<br>       [-C minimum number of samples (default 0)]
<br>       [-D duration in msecs (default 10s)]
<br>       [-E (echo name to stderr)]
<br>       [-H] (suppress headers)
<br>       [-I] specify approx. time per op in nsecs
<br>       [-L] (print argument line)
<br>       [-M] (reports mean rather than median)
<br>       [-N test-name ]
<br>       [-P processes (default 1)]
<br>       [-S] (print detailed stats)
<br>       [-T threads (default 1)]
<br>       [-V] (print the libMicro version and exit)
<br>       [-W] (flag possible benchmark problems)
<br>
<br>
<br>Apple-added Benchmarks
<br>-----------------------
<br>
<br>	create_file
<br>	geekbench_stdlib_write
<br>	getaddrinfo_port
<br>	getaddrinfo_host
<br>	getgrgid
<br>	getgrent
<br>	getgrnam
<br>	getppid
<br>	getpwnam
<br>	getpwuid
<br>	getpwent
<br>	lb_mmtest
<br>	lm_null_call
<br>	lmbench_bw_file_rd
<br>	lmbench_bw_mem
<br>	lmbench_bw_mmap_rd
<br>	lmbench_bw_unix
<br>	lmbench_fstat
<br>	lmbench_lat_ctx
<br>	lmbench_lat_sig_catch
<br>	lmbench_lat_sig_install
<br>	lmbench_lat_sig_prot
<br>	lmbench_lat_sig_send
<br>	lmbench_openclose
<br>	lmbench_read
<br>	lmbench_select_file
<br>	lmbench_select_tcp
<br>	lmbench_stat
<br>	lmbench_write
<br>	mbr_check_service_membership
<br>	mbr_check_membership
<br>	od_query_create_with_node
<br>	trivial
<br>	vm_allocate
<br>
<br>Also, please read AppleReadMe for further information.
<br>
<br><p></p><div class="separator"></div><br><p><h2>MPMMTest</h2></p>MPMMTest / KQMPMMTest
<br>
<br>These tests measure the speed of IPC with mach messaging and kqueues. To build,
<br>simply run make. A 32- and 64-bit version of each test will be generated by
<br>default. Each test can be run without options:
<br>
<br>$ ./MPMMtest
<br>1 server, 4 clients per server (4 total) 400000 messages... in 4.820 seconds
<br>  throughput in messages/sec:     82978.7
<br>  average message latency (usec): 12.1
<br>
<br>and will report the latency and throughput that the server achieved. The user
<br>can change the number of servers and clients, the flavor of message, and other
<br>variables with command line options--run './MPMMtest -h' for details.
<br>
<br><p></p><div class="separator"></div><br><p><h2>perf_index</h2></p>perf_index - This is a tool for gather performance data. perf_index can run in
<br>two modes. In regulular (offline mode) the usage is:
<br>pref_index type threads size [args]
<br>where type is one of the test types explained below, threads is the number of
<br>userland threads that should preform the task, size is the size of the task and
<br>args are arguments to pass to the test. Currently only the iperf test requires
<br>these arguments. For example if run with the following arguments:
<br>./perf_index cpu 2 100000000
<br>
<br>iperf will run the cpu workload on two threads with a total work load size of
<br>100000000. Since the workload is distributed over 2 threads, on a perfectly
<br>parallel system, this would take half the time relative to if 1 was specified
<br>for the threads parameter. When finished running perf_index will write the
<br>number of seconds it took to standard out as a decimal number. Some of the test
<br>types have initialization and teardown steps, and these steps are not counted
<br>towards the time.  The workload and the time it takes to be performed differs
<br>quite drastically between test type, so you may need to play around with the
<br>size argument to find a value that will complete in a reasonable amount of time.
<br>
<br>In online mode, perf_index is invoked like so:
<br>perf_index remote server
<br>where remote is exactly the string "remote" and server is the control host to
<br>connect to.  This tells the program to connect to the specified server and wait
<br>for instructions. The server is run by running the test_controller.py python
<br>script with the following arguments:
<br>test_controller.py num_clients type threads size
<br>The server will wait for num_client to connect. It will then pass type, threads,
<br>and size to each of those clients, who will run the initialization code and
<br>report back to the server. Once the initialization is run by every client, the
<br>server will give the OK to every client to run the workload and begin timing.
<br>When done, each client reports back to the server. Once the server hears back
<br>from every client, it will stop timing and output the elapsed time.
<br>
<br>
<br>Test Types:
<br>Note this implementations are subject to change, for an authoritative source,
<br>see the source code
<br>cpu - calculates n md5 sums
<br>memory - initializes by allocating memory equal to half the RAM on the machine,
<br>then writes a byte to every page to ensure it is paged in. Then copies n bytes
<br>from the first half of memory to the second. If the allocated space is less than
<br>n/2, it keeps repeating the copies until n bytes are copied.
<br>syscall - calls the getppid(2) system call n times
<br>fault - performs n page faults by mmaping a large chunk of memory, toggling the
<br>write protection bit, and writing to each page
<br>zfod - performs n zero fill on demands, by mmaping a large chunk of memory and
<br>writing to each page
<br>file_create - creates n files (in the same directory) with the open(2) system
<br>call
<br>file_write - writes n bytes to files on disk. There is one file per each thread.
<br>file_read - initializes by creating one large file on disk per each thread.
<br>Then reads n bytes total from all the files. If there are less than n bytes in
<br>the files, repeats reading from the beginning.
<br>ram_file_create - same as file_create but on a ram disk
<br>ram_file_read - same as file_read but on a ram disk
<br>ram_file_write - same as file_write but on a ram disk
<br>iperf - uses iperf to send n bytes over the network to the designated host
<br>specified as args
<br>compile - compiles xnu using make. This currently does a single compile and
<br>ignores the size argument
<br>
<br>Building:
<br>perf_index is built automatically by BNI for both Mac (10.9 and later), and iOS
<br>(7 and later) trains, and is delivered on AppleInternal builds in
<br>/AppleInternal/CoreOS/perf_index. It is built as part of the xnu_quick_test
<br>build alias, so you can also find a copy on ~rc at:
<br>~rc/Software/$RELEASE/Updates/$RELEASEVERSION/Roots/xnu_quick_test/AppleInternal/CoreOS/perf_index.
<br>
<br>Alternatively you can build it yourself using make like so:
<br>SDKROOT=/path/to/sdk make
<br>
<br>For example:
<br># build for Mac, current OS
<br>SDKROOT=/ make
<br># build for iOS
<br>SDKROOT=`xcodebuild -sdk iphoneos.internal -version Path` make
<br>
<br>By default xnu builds all-way fat, but you can restrict this by explicitly
<br>specifying architectures like so:
<br># build for only armv7 and armv7s
<br>SDKROOT=`xcodebuild -sdk iphoneos.internal -version Path` make ARCH="armv7 armv7s"
<br><p></p><div class="separator"></div><br><p><h2>Deer</h2></p>Copyright (C) 2017 by ATPC
<br>
<br>	This program is free software: you can redistribute it and/or modify
<br>	it under the terms of the GNU Affero General Public License as
<br>	published by the Free Software Foundation, either version 3 of the
<br>	License, or (at your option) any later version.
<br>
<br>	This program is distributed in the hope that it will be useful,
<br>	but WITHOUT ANY WARRANTY; without even the implied warranty of
<br>	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<br>	GNU Affero General Public License for more details.
<br>
<br>    You should have received a copy of the GNU Affero General Public License
<br>    along with this program.  If not, see <http://www.gnu.org/licenses/>.
<br><p></p><div class="separator"></div><br><p><h2>Caffeine</h2></p>Copyright (C) 2017 by ATPC
<br>
<br>	This program is free software: you can redistribute it and/or modify
<br>	it under the terms of the GNU Lesser General Public License as
<br>	published by the Free Software Foundation, either version 3 of the
<br>	License, or (at your option) any later version.
<br>
<br>	This program is distributed in the hope that it will be useful,
<br>	but WITHOUT ANY WARRANTY; without even the implied warranty of
<br>	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<br>	GNU Lesser General Public License for more details.
<br>
<br>	You should have received a copy of the GNU Lesser General Public License
<br>	along with this program.  If not, see <http://www.gnu.org/licenses/>.
<br><p></p><div class="separator"></div><br><p><h2>libc</h2></p>Copyright (C) 2017 by ATPC
<br>
<br>	This program is free software: you can redistribute it and/or modify
<br>	it under the terms of the GNU Lesser General Public License as
<br>	published by the Free Software Foundation, either version 3 of the
<br>	License, or (at your option) any later version.
<br>
<br>	This program is distributed in the hope that it will be useful,
<br>	but WITHOUT ANY WARRANTY; without even the implied warranty of
<br>	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<br>	GNU Lesser General Public License for more details.
<br>
<br>	You should have received a copy of the GNU Lesser General Public License
<br>	along with this program.  If not, see <http://www.gnu.org/licenses/>.
<br><p></p><div class="separator"></div><br><p><h2>xcrun</h2></p><img src="http://www.apfelpage.de/wp-content/uploads/2013/12/Xcode.png" alt="Xcode logo" height="70">
<br># ATPC xcrun
<br>Open source version of xcrun.
<br>
<br>## Getting Started
<br>**Via HTTPS** For those checking out sources as read-only, HTTPS works best:
<br>```
<br>git clone https://github.com/atpcorg/xcrun.git
<br>```
<br>
<br>To build xcrun, just invoke
<br>```
<br>make
<br>```
<br>
<br>The finished file will be in the `dist` folder.
<br>
<br>## Credits
<br>Copyright (C) 2016 by ATPC  
<br>  
<br>    This program is free software: you can redistribute it and/or modify
<br>    it under the terms of the GNU Affero General Public License as
<br>    published by the Free Software Foundation, either version 3 of the
<br>    License, or (at your option) any later version.
<br>  
<br>    This program is distributed in the hope that it will be useful,
<br>    but WITHOUT ANY WARRANTY; without even the implied warranty of
<br>    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<br>    GNU Affero General Public License for more details.
<br>  
<br>    You should have received a copy of the GNU Affero General Public License
<br>    along with this program.  If not, see <http://www.gnu.org/licenses/>.
<br>
<br><p></p><div class="separator"></div><br><p><h2>include</h2></p>Common C/C++/Objective-C header files for the standard library.
<br>
<br>Copyright (C) 2017 by ATPC
<br>
<br>	This program is free software: you can redistribute it and/or modify
<br>    it under the terms of the GNU Lesser General Public License as
<br>    published by the Free Software Foundation, either version 3 of the
<br>    License, or (at your option) any later version.
<br>
<br>    This program is distributed in the hope that it will be useful,
<br>    but WITHOUT ANY WARRANTY; without even the implied warranty of
<br>    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<br>    GNU Lesser General Public License for more details.
<br>
<br>    You should have received a copy of the GNU Lesser General Public License
<br>    along with this program.  If not, see <http://www.gnu.org/licenses/>.
<br>
<br>
<br>	NOTE:
<br>	This product includes software developed by the tyndur Project
<br>	and its contributors.
<br><p></p><div class="separator"></div><br><p><h2>services</h2></p>Description
<br>===========
<br>
<br>A service is a core functionality and an API for adding kernel-like features to
<br>the userland.
<br>
<br>To use services in your own system, you'll have to implement these headers (and, obviously, some C APIs):
<br><services/servicelib.h>
<br><services/randomseed.h>
<br>
<br>
<br>Credits
<br>=======
<br>
<br>Copyright (C) 2017 by ATPC
<br>
<br>	This program is free software: you can redistribute it and/or modify
<br>	it under the terms of the GNU Affero General Public License as
<br>	published by the Free Software Foundation, either version 3 of the
<br>	License, or (at your option) any later version.
<br>
<br>	This program is distributed in the hope that it will be useful,
<br>	but WITHOUT ANY WARRANTY; without even the implied warranty of
<br>	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
<br>	GNU Affero General Public License for more details.
<br>
<br>    You should have received a copy of the GNU Affero General Public License
<br>    along with this program.  If not, see <http://www.gnu.org/licenses/>.
<br></div></body></html>
